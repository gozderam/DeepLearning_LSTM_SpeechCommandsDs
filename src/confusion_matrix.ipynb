{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from data_utils import data_loading as data_load\n",
    "from data_utils import classes_labels as cl\n",
    "from custom_nets.cnn import CNNAll, CNN3Classes, CNN10Classes\n",
    "from custom_nets.lstm_simple_all_classes import LSTMSimpleAll\n",
    "from custom_nets.resnet_all_classes import ResBlock, ResNetAll\n",
    "from custom_nets.lstm_cnn_all_classes import LSTMCNNAll\n",
    "from custom_nets.lstm_cnn_pqd_all_classes import LSTMCNNAllpqd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.pylabtools import figsize\n",
    "import ntpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfusionMatrixAll:\n",
    "    def __init__(self, batch_size, device):\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.testloader, self.number_of_audio = data_load.load_validation_as_test_data(self.batch_size, '../data')\n",
    "        if not os.path.exists('../confusion_matrices'):\n",
    "            os.makedirs('../confusion_matrices')\n",
    "    \n",
    "    def save_confusion_matrix(self, network, best_networkstate_path):\n",
    "        \n",
    "        classes = np.empty((self.number_of_audio), dtype=object)\n",
    "        proper_classes = np.empty((self.number_of_audio), dtype=object)\n",
    "        if self.device == 'cpu':\n",
    "            network.load_state_dict(torch.load(best_networkstate_path, map_location=torch.device('cpu')))\n",
    "        else:\n",
    "            network.load_state_dict(torch.load(best_networkstate_path))\n",
    "        network.to(self.device)\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in self.testloader:\n",
    "                images, file_names = data[0].to(self.device), data[1]\n",
    "                outputs = network(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                predicted = predicted.tolist()\n",
    "                for i, predicted_label in enumerate(predicted):\n",
    "                    classes[total] = cl.label_number_to_class[predicted_label]\n",
    "                    proper_classes[total] = cl.label_number_to_class[cl.class_to_label_number[file_names[i].split('/')[0]]]\n",
    "                    total += 1\n",
    "\n",
    "        labels = list(cl.label_number_to_class2.values())\n",
    "        conf_mat = confusion_matrix(proper_classes, classes, labels=labels)\n",
    "        pd.DataFrame(conf_mat, index=labels, columns=labels).to_csv(f'../confusion_matrices/{ntpath.basename(best_networkstate_path[:-4])}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfusionMatrixTwoNets:\n",
    "    def __init__(self, batch_size, device):\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.testloader, self.number_of_audio = data_load.load_validation_as_test_data(self.batch_size, '../data')\n",
    "        if not os.path.exists('../confusion_matrices'):\n",
    "            os.makedirs('../confusion_matrices')\n",
    "    \n",
    "    def save_confusion_matrix(self, network, network2, best_networkstate_path, best_networkstate_path2):\n",
    "        \n",
    "        classes = np.empty((self.number_of_audio), dtype=object)\n",
    "        proper_classes = np.empty((self.number_of_audio), dtype=object)\n",
    "        \n",
    "        if self.device == 'cpu':\n",
    "            network.load_state_dict(torch.load(best_networkstate_path, map_location=torch.device('cpu')))\n",
    "        else:\n",
    "            network.load_state_dict(torch.load(best_networkstate_path))\n",
    "        network.to(self.device)\n",
    "        if self.device == 'cpu':\n",
    "            network2.load_state_dict(torch.load(best_networkstate_path2, map_location=torch.device('cpu')))\n",
    "        else:\n",
    "            network2.load_state_dict(torch.load(best_networkstate_path2))\n",
    "        network2.to(self.device)\n",
    "        \n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in self.testloader:\n",
    "                images, file_names = data[0].to(self.device), data[1]\n",
    "                \n",
    "                outputs = network(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                predicted = predicted.tolist()\n",
    "                \n",
    "                outputs2 = network2(images)\n",
    "                _, predicted2 = torch.max(outputs2.data, 1)\n",
    "                predicted2 = predicted2.tolist()\n",
    "                \n",
    "                for i, predicted_label in enumerate(predicted):\n",
    "                    class_name = cl.label_number_to_class1[predicted_label]\n",
    "                    if class_name == 'valid':\n",
    "                        class_name = cl.label_number_to_class2[predicted2[i] + 2]\n",
    "                    classes[total] = class_name\n",
    "                    proper_classes[total] = cl.label_number_to_class[cl.class_to_label_number[file_names[i].split('/')[0]]]\n",
    "                    total += 1\n",
    "        \n",
    "        labels = list(cl.label_number_to_class2.values())\n",
    "        conf_mat = confusion_matrix(proper_classes, classes, labels=labels)\n",
    "        pd.DataFrame(conf_mat, index=labels, columns=labels).to_csv(f'../confusion_matrices/{ntpath.basename(best_networkstate_path[:-4])}_{ntpath.basename(best_networkstate_path2[:-4])}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfusionMatrixVisualizer:\n",
    "    \n",
    "    @staticmethod\n",
    "    def visualize(confusion_matrix_path):\n",
    "        figsize(7, 7)\n",
    "        if not os.path.exists('../confusion_matrices_pdfs'):\n",
    "            os.makedirs('../confusion_matrices_pdfs')\n",
    "        \n",
    "        matrix = pd.read_csv(confusion_matrix_path, index_col='Unnamed: 0')\n",
    "        \n",
    "        index = list(matrix.index)\n",
    "        cols = list(matrix.columns)\n",
    "        conf_data = np.array(matrix)\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        cmap = plt.cm.get_cmap(\"PuBuGn\", 3000)\n",
    "        im = ax.imshow(conf_data, cmap=cmap, vmin=0, vmax=200)\n",
    "\n",
    "        # Show all ticks and label them with the respective list entries.\n",
    "        ax.set_xticks(np.arange(len(index)), labels=index, fontsize=12)\n",
    "        ax.set_yticks(np.arange(len(cols)), labels=cols, fontsize=12)\n",
    "\n",
    "        # Rotate the tick labels and set their alignment.\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha='right',\n",
    "                rotation_mode='anchor')\n",
    "\n",
    "        # Loop over data dimensions and create text annotations.\n",
    "        for i in range(len(cols)):\n",
    "            for j in range(len(index)):\n",
    "                col = 'white' if conf_data[i, j] > 100 else 'black'\n",
    "            \n",
    "                ax.text(j, i, conf_data[i, j],\n",
    "                            ha='center', va='center', color=col, fontsize=12)\n",
    "\n",
    "        ax.set_xlabel('predicted', fontsize=12)\n",
    "        ax.set_ylabel('true', fontsize=12)\n",
    "        fig.tight_layout()\n",
    "\n",
    "        fig_png_path = os.path.join('../confusion_matrices_pdfs', ntpath.basename(confusion_matrix_path[:-4]) + '.pdf')\n",
    "        if os.path.isfile(fig_png_path):\n",
    "            os.remove(fig_png_path)\n",
    "        plt.savefig(fig_png_path)\n",
    "\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe0172e525c335d9d8cafeee118aa872bf99843faad0080e311f444d1604a5dd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
